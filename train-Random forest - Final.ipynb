{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code here represents the Random Forest Regressor machine learning model to predict whether a person is affected by covid or pneumonia or whether the person is in normal state using the chest X-Ray. The Chest X-Ray images have been preproccessed and then the features have been extracted and stored in .mat files. We now load these files and create the Random Forest Regressor model. We also print different error values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required packages\n",
    "from utils import*\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentioning the working directory\n",
    "source_dir='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing covid.mat file and getting the data from the file\n",
    "covid_features=sio.loadmat(os.path.join(source_dir,'covid.mat')) \n",
    "covid_features=covid_features['covid'] \n",
    "# Accessing normal.mat file and getting the data from the file\n",
    "normal_features=sio.loadmat(os.path.join(source_dir,'normal.mat')) \n",
    "normal_features=normal_features['normal']  \n",
    "# Accessing pneumonia.mat file and getting the data from the file\n",
    "pneumonia_features=sio.loadmat(os.path.join(source_dir,'pneumonia.mat')) \n",
    "pneumonia_features=pneumonia_features['pneumonia']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the scores-i.e the inputs and storing it in X\n",
    "X=np.concatenate((covid_features[:,:-1],normal_features[:,:-1],pneumonia_features[:,:-1]), axis=0)\n",
    "# Extracting the target labels, the last column alone\n",
    "y=np.concatenate((covid_features[:,-1],normal_features[:,-1],pneumonia_features[:,-1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of the data between 0 and 1\n",
    "min_max_scaler=MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Kernel to reduce the feature components to 64 for the input data\n",
    "transformer = KernelPCA(n_components=64, kernel='linear')\n",
    "X = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the splitting of data set and set the training data to be 80% ,i.e, test data = 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# From that 80%, test data fraction is set as 25% to get a better output as there is more randomness in the dataset for testing\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data: (225, 64)\n",
      "Size of train label: (225,)\n",
      "Size of test data: (76, 64)\n",
      "Size of test label: (76,)\n"
     ]
    }
   ],
   "source": [
    "# Printing the size for each of the data\n",
    "print(\"Size of train data:\", np.shape(X_train))\n",
    "print(\"Size of train label:\", np.shape(y_train))\n",
    "print(\"Size of test data:\", np.shape(X_test))\n",
    "print(\"Size of test label:\", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Random Forest Regressor Object that will create 20 trees\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "# Training the model\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting/ testing the model\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.22236842105263155\n",
      "Mean Squared Error: 0.10585526315789473\n",
      "Root Mean Squared Error: 0.3253540581549502\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
